# -*- coding: utf-8 -*-
"""Tải thư viện"""

#!pip install torch
#!pip install torch_geometric

"""Import thư viện"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import kneighbors_graph
import torch
import numpy as np
from torch_geometric.data import Data
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
import os
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA

"""Đọc dataset được lấy từ: https://www.kaggle.com/datasets/amauricio/pe-files-malwares"""

data_malware = pd.read_csv('D:\\project\\IE105\\GNN_For_PE_File\\dataset_malwares.csv')
data_test = pd.read_csv('D:\\project\\IE105\\GNN_For_PE_File\\dataset_test.csv')

data_malware.head(5)

data_malware.info()

dropped_data_malware = data_malware.drop(['Name', 'Machine', 'TimeDateStamp', 'Malware'], axis=1)

plt.figure(figsize=(8, 6))
data_malware['Malware'].value_counts().plot.bar()
plt.xticks([1,0], ['Benign', 'Malware'])
plt.xlabel('Malware')
plt.ylabel('Count')
plt.title('Biểu đồ phân lớp dữ liệu')
plt.show()

features_1 = ['MajorSubsystemVersion', 'MajorLinkerVersion', 'SizeOfCode', 'SizeOfImage', 'SizeOfHeaders', 'SizeOfInitializedData',
           'SizeOfUninitializedData', 'SizeOfStackReserve', 'SizeOfHeapReserve',
            'NumberOfSymbols', 'SectionMaxChar']
i=1

for features_1 in features_1:
    plt.figure(figsize=(10, 15))
    ax1 = plt.subplot(len(features_1), 2, i)
    sns.distplot(data_malware[data_malware['Malware']==1][features_1], ax=ax1, kde_kws={'bw': 0.1})
    ax1.set_title(f'Malware', fontsize=10)
    ax2 = plt.subplot(len(features_1), 2, i+1)
    sns.distplot(data_malware[data_malware['Malware']==0][features_1], ax=ax2, kde_kws={'bw': 0.1})
    ax2.set_title(f'Benign', fontsize=10)
    i= i+2

# Columns in the dataset
columns = data_malware.columns.tolist()

# Identify feature columns (exclude 'Name' and 'Malware')
feature_columns = [col for col in columns if col in ['MajorSubsystemVersion', 'MajorLinkerVersion', 'SizeOfCode', 'SizeOfImage', 'SizeOfHeaders', 'SizeOfInitializedData',
           'SizeOfUninitializedData', 'SizeOfStackReserve', 'SizeOfHeapReserve',
            'NumberOfSymbols', 'SectionMaxChar']]

# Label column
label_column = 'Malware'

# Print the identified feature columns
print(f"Feature columns: {feature_columns}")
print(f"Label column: {label_column}")

#Lay cac cot tinh nang va cot nhan
# data_malware = data_malware.columns[1:-1]
# label_column = 'Malware'

#Chuan hoa cac tinh nang
scaler = StandardScaler()
features = scaler.fit_transform(data_malware[feature_columns])
labels = data_malware[label_column].values

k = 5
try:
    knn_graph = kneighbors_graph(features, k, mode='connectivity', include_self=False)
    print(f"Shape of knn_graph: {knn_graph.shape}")
    edge_index = torch.tensor(np.array(knn_graph.nonzero()), dtype=torch.long)
    print(f"Shape of edge_index: {edge_index.shape}")
except ValueError as e:
    print(f"Error in kneighbors_graph: {e}")

# Convert features and labels to PyTorch tensors
x = torch.tensor(features, dtype=torch.float)
y = torch.tensor(labels, dtype=torch.long)

# Create a PyTorch Geometric Data object
graph_data = Data(x=x, edge_index=edge_index, y=y)

tsne = TSNE(n_components=2, random_state=42)
z = tsne.fit_transform(x.numpy())

# Prepare colors for different classes
colors = ['red' if label == 1 else 'blue' for label in labels]

# Visualize using scatter plot
plt.figure(figsize=(10, 10))
plt.xticks([])
plt.yticks([])
plt.scatter(z[:, 0], z[:, 1], c=colors, cmap="Set2")
plt.title("Visualization of the Dataset")
plt.show()

# Define the GNN model
class GCN(torch.nn.Module):
    def __init__(self, in_channels, out_channels):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(in_channels, 16)
        self.conv2 = GCNConv(16, out_channels)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)

# Initialize the model, optimizer, and loss function
model = GCN(in_channels=graph_data.num_features, out_channels=2)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.CrossEntropyLoss()

# Training the GNN model
def train():
    model.train()
    optimizer.zero_grad()
    out = model(graph_data)
    loss = criterion(out, graph_data.y)
    loss.backward()
    optimizer.step()
    return loss

# Test the GNN model
def test():
  model.eval()
  out = model(graph_data)
  pred = out.argmax(dim=1)
  test_correct = pred[graph_data.test_mask] == graph_data.y[graph_data.test_mask]
  test_acc = int(test_correct.sum()) / int(graph_data.test_mask.sum())
  return test_acc

# Training loop
for epoch in range(500):
    loss = train()
    if epoch % 20 == 0:
        print(f'Epoch {epoch}, Loss: {loss:.4f}')

test_acc = test()
print(f'Test Accuracy: {test_acc:.4f}')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

def visualize(h):
  z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())

  # Prepare colors for different classes
  colors = ['red' if label == 1 else 'blue' for label in labels]

  # Visualize using scatter plot
  plt.figure(figsize=(10, 10))
  plt.xticks([])
  plt.yticks([])
  plt.scatter(z[:, 0], z[:, 1], c=colors, cmap="Set2")
  plt.title("Visualization of the Dataset")
  plt.show()

model.eval()

out = model(graph_data)
visualize(out)

# Save the trained model
model_save_path = 'D:\\project\\IE105\\GNN_For_PE_File\\trained_gcn_model.pth'
optimizer_save_path = 'D:\\project\\IE105\\GNN_For_PE_File\\optimizer.pth'

torch.save(model.state_dict(), model_save_path)
torch.save(optimizer.state_dict(), optimizer_save_path)

print("Model saved successfully.")

# To load the model later
loaded_model = GCN(in_channels=graph_data.num_features, out_channels=2)
loaded_optimizer = torch.optim.Adam(loaded_model.parameters(), lr=0.01)

loaded_model.load_state_dict(torch.load(model_save_path))
loaded_optimizer.load_state_dict(torch.load(optimizer_save_path))

print("Model loaded successfully.")

scaler = StandardScaler()
scaler.fit(data_test[feature_columns])  # Assuming 'data' is the training dataset DataFrame
test_features = scaler.transform(data_test[feature_columns])

